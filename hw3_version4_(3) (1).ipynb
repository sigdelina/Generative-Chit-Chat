{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rblFRypAtIT",
        "outputId": "c00b2f1d-ad0c-4bf7-de20-6e632c986609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: youtokentome in /usr/local/lib/python3.8/dist-packages (1.0.6)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.8/dist-packages (from youtokentome) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install youtokentome"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7mMhgZ1A1GE",
        "outputId": "72a656d4-b143-4abe-8947-0ee82df7a732"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import youtokentome as yttm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "T7ETs0-yA3MM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/комплинг/дз3'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf3c67OzBBGM",
        "outputId": "38ea934e-e351-47f7-ce48-9bd6213c9d6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/комплинг/дз3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "   \n",
        "    def __init__(self, path_to_file, sep='\\t'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.path_to_file = path_to_file\n",
        "        self.sep = sep\n",
        "        \n",
        "        self.data = self.load_data()\n",
        "        self.train, self.val, self.test = self.split_dataset()\n",
        "        self.dataframe = pd.DataFrame({'question': self.data[0], 'answer': self.data[1]})\n",
        "    \n",
        "\n",
        "    def load_data(self):        \n",
        "        data_seq = []\n",
        "        question, answer = [], []\n",
        "        counter = 0\n",
        "        with open(self.path_to_file,) as f:\n",
        "            for line in f:\n",
        "                if counter == 400000:\n",
        "                  break\n",
        "                data_seq.append(line.strip().split(self.sep))\n",
        "                counter += 1\n",
        "                # data = line.strip().split(self.sep)\n",
        "                # question.append(data[0])\n",
        "                # answer.append(data[1])\n",
        "        return data_seq\n",
        "    \n",
        "\n",
        "    def prepare_tokenization(self):\n",
        "\n",
        "      with open('for_bpe.txt', 'w', encoding='utf-8') as f:\n",
        "        for que, answ in self.train:\n",
        "            f.write(que + '\\t' + answ + '\\n')\n",
        "      \n",
        "\n",
        "    def split_dataset(self):\n",
        "      \n",
        "      train, val, test = np.split(np.array(self.data), [int(.8 * len(self.data)), int(.9 * len(self.data))])\n",
        "\n",
        "      return train, val, test"
      ],
      "metadata": {
        "id": "eD-46fxtBDE6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TrainDataset('train.txt')\n",
        "train, dev, test = dataset.train, dataset.val, dataset.test"
      ],
      "metadata": {
        "id": "txIRJTMWBH4p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.prepare_tokenization()"
      ],
      "metadata": {
        "id": "ZNN1nbMxBLWg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 30_000\n",
        "model_path = 'pretrained_bpe_lm.model'\n",
        "yttm.BPE.train(data='for_bpe.txt', vocab_size=vocab_size, model=model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inb2981jBNR0",
        "outputId": "7cc6695d-f1f5-475b-bb8c-699e2d051891"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<youtokentome.youtokentome.BPE at 0x7fb27607a6a0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "    \n",
        "    def __init__(self, model_path, max_length):\n",
        "      \n",
        "        self.tokenizer = yttm.BPE(model=model_path)\n",
        "        \n",
        "        self.tokenizer.pad_token = '<pad>'\n",
        "        self.pad_index = 0\n",
        "        self.max_length = max_length\n",
        "\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"\n",
        "        В этом методе нужно разделить строку текста на токены\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "        return self.tokenizer.encode(text, bos=True, eos=True)\n",
        "\n",
        "        \n",
        "    def padding(self, tokens_indices):\n",
        "        \"\"\"\n",
        "        В этом методе нужно сделать длину tokens_indices равной self.max_length\n",
        "        \"\"\"\n",
        "        ...        \n",
        "        padded_seq = F.pad(torch.tensor(tokens_indices), (0,  self.max_length - len(tokens_indices)), value=self.pad_index)\n",
        "\n",
        "        return padded_seq\n",
        "\n",
        "    \n",
        "    def __call__(self, text):\n",
        "        \"\"\"\n",
        "        В этом методе нужно перевести строку с текстом в вектор с индексами слов нужно размера (self.max_length)\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "        return torch.LongTensor(self.padding(self.tokenize(text)))\n",
        "\n",
        "    \n",
        "    def no_eos(self, text):\n",
        "         return torch.LongTensor(self.padding(self.tokenizer.encode(text, bos=True, eos=False)))\n",
        "\n",
        "\n",
        "    def collate(self, batch):\n",
        "        \n",
        "        question = torch.stack([self.__call__(el[0]) for el in batch])\n",
        "\n",
        "        answer = torch.stack([self.__call__(el[1]) for el in batch])\n",
        "\n",
        "        answer_no_eos = torch.stack([self.no_eos(el[1]) for el in batch])\n",
        "\n",
        "        return question, answer, answer_no_eos"
      ],
      "metadata": {
        "id": "zKq2ilmnBNZY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(model_path, 64)"
      ],
      "metadata": {
        "id": "b_jFf8GBBTTv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train, batch_size=64, shuffle=True, collate_fn=lambda x: tokenizer.collate(x))\n",
        "dev_loader = DataLoader(dev, batch_size=64, shuffle=True, collate_fn=lambda x: tokenizer.collate(x))\n",
        "test_loader = DataLoader(test, batch_size=64, shuffle=True, collate_fn=lambda x: tokenizer.collate(x))"
      ],
      "metadata": {
        "id": "rNISpjgGBTZx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y, y_no_eos in train_loader:\n",
        "    break"
      ],
      "metadata": {
        "id": "7xMbzKH5BYEg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, y.shape, y_no_eos.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V0zo7MlBZ8o",
        "outputId": "dd555d16-95c9-42b2-a651-76fecdb4e320"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 64]), torch.Size([64, 64]), torch.Size([64, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar = tqdm(total=len(dev_loader.dataset), desc='Evaluation')\n",
        "\n",
        "for x, y, _ in dev_loader:\n",
        "    progress_bar.update(x.size(0))\n",
        "    \n",
        "progress_bar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zSM1VYVBbuY",
        "outputId": "2ab4cc2c-98e1-4eea-af39-8f157d332ec7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 40000/40000 [00:03<00:00, 11566.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_loader.dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlDBrJSIBe7X",
        "outputId": "9e516f16-ab7b-4aa0-90d4-e2ee847d3a0f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['можа хватит уже чревоугодничать и будем прелюбодействовать,а?)',\n",
              "        'погоди., ещё не допили. дринк!. а вообще назрел вопрос.!'],\n",
              "       ['самы дарогой вит спорта', 'для нашей страны футбол.'],\n",
              "       ['отправьте мне фото которое является самым красивым в мире',\n",
              "        'для каждого свое. мне нравится например это ---&gt;'],\n",
              "       ...,\n",
              "       ['сударыня вы пишете душою?',\n",
              "        'сердцем . а я вот спросить хотела , а кому это надо?'],\n",
              "       ['эй? у тебя есть душа?', 'после праздников найти надо будет.'],\n",
              "       ['как перестать слушать \"медузу\" ?', 'нажать кнопочку \"выкл.\"']],\n",
              "      dtype='<U64')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder CNN"
      ],
      "metadata": {
        "id": "v8ZLxQqoCPtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = vocab_size\n",
        "OUTPUT_DIM = vocab_size\n",
        "KERNEL_SIZE = 2\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 100\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 1"
      ],
      "metadata": {
        "id": "PkU_DL3bHiLj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "   def __init__(self, hid_dim, device):\n",
        "      super().__init__()\n",
        "\n",
        "      # сверточные слои\n",
        "      self.conv1 = nn.Conv1d(in_channels=hid_dim, \n",
        "                               out_channels=hid_dim,\n",
        "                               kernel_size=3,\n",
        "                               padding = 1)\n",
        "        \n",
        "      self.conv2 = nn.Conv1d(in_channels=hid_dim, \n",
        "                               out_channels=hid_dim,\n",
        "                               kernel_size=5,\n",
        "                               padding = 2)\n",
        "\n",
        "      self.batch_norm = nn.BatchNorm1d(hid_dim)\n",
        "      self.activ = nn.ReLU()\n",
        "      self.scale = torch.sqrt(torch.FloatTensor([0.4])).to(device)\n",
        "      self.device = device\n",
        "    \n",
        "   def forward(self, to_conv_perm):\n",
        "      \n",
        "      # сверточные слои\n",
        "      conv1 = self.conv1(to_conv_perm)  # [batch, hid_dim, len_sent]\n",
        "      conv1 = self.batch_norm(conv1)\n",
        "      # при gelu, out_chanels должен задаваться как 2 * hid_dim, так как в ней зашито деление на 2\n",
        "      conv1 = self.activ(conv1)  # [batch, hid_dim, len_sent]\n",
        "      conv_after_resid = (to_conv_perm + conv1) * self.scale  # [batch, hid_dim, len_sent]\n",
        "\n",
        "\n",
        "      conv2 = self.conv2(conv_after_resid)  # [batch, hid_dim, len_sent]\n",
        "      conv2 = self.batch_norm(conv2)\n",
        "      conv2 = self.activ(conv2)  # [batch, hid_dim, len_sent]\n",
        "      conv_after_2resid = (conv_after_resid + conv2) * self.scale  # [batch, hid_dim, len_sent]\n",
        "\n",
        "        \n",
        "      # смена размерности для линейного слоя\n",
        "      to_out_lin = conv_after_2resid.permute(0, 2, 1)  # [batch, len_sent, hid_dim]\n",
        "\n",
        "      return to_out_lin"
      ],
      "metadata": {
        "id": "LygyqT0ToYma"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, kernel_s, device, max_length=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # инициализируем эмбеддинги для токенов и их позиций (от первого токена до последнего)\n",
        "        self.position_embedding = nn.Embedding(max_length, emb_dim)\n",
        "        self.token_embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        # линейные слои\n",
        "        self.linear_toblock = nn.Linear(emb_dim, hid_dim)\n",
        "        self.linear_outblock = nn.Linear(hid_dim, emb_dim)\n",
        "\n",
        "        # сверточные слои\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([0.4])).to(device)\n",
        "        self.conv_b = ConvBlock(hid_dim, device)\n",
        "        self.device = device\n",
        "      \n",
        "    def forward(self, b_elem):\n",
        "\n",
        "        batch_size = b_elem.shape[0]  # размер батча \n",
        "        src_len = b_elem.shape[1]    # длина последовательности\n",
        "\n",
        "        # генерация матрицы тензора для позиций слов: [batch, len_sent]\n",
        "        posintion_t = torch.stack([torch.arange(0, src_len) for pos in range(batch_size)]).to(self.device)\n",
        "        # получаем эмбеддинги: [batch, len_sent, embed_dim]\n",
        "        tok_emb = self.token_embedding(b_elem.to(self.device))\n",
        "\n",
        "\n",
        "        pos_emb = self.position_embedding(posintion_t)\n",
        "\n",
        "        # elemenwise sum: [batch, len_sent, embed_dim]\n",
        "        elem_wise = tok_emb + pos_emb  # тут еще можно добавить дропаут\n",
        "        \n",
        "        # линейные слой: [batch, len_sent, hid_dim]\n",
        "        to_block = self.linear_toblock(elem_wise)\n",
        "\n",
        "        # входная размерность в conv - (N,C,L), где L - длина последоваетльности, С - число каналов \n",
        "        # [batch, hid_dim, len_sent]\n",
        "        to_conv_perm = to_block.permute(0, 2, 1)\n",
        "\n",
        "        \n",
        "\n",
        "        # # сверточные слои       \n",
        "        to_out_lin = self.conv_b(to_conv_perm)\n",
        "\n",
        "        # линейный слой\n",
        "        out_lin = self.linear_outblock(to_out_lin)  # [batch, len_sent, emb_dim]\n",
        "        \n",
        "        # residual connection\n",
        "        res_con_out = (out_lin + elem_wise) * self.scale  # [batch, len_sent, emb_dim]\n",
        "\n",
        "        return out_lin, res_con_out"
      ],
      "metadata": {
        "id": "u3Btz6BTCT-H"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, KERNEL_SIZE)\n",
        "# out_lin, res_con = encoder(x)"
      ],
      "metadata": {
        "id": "bqPF07mUHUjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder CNN"
      ],
      "metadata": {
        "id": "B_Fm4DhVACCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self,emb_size,hid_size, device):\n",
        "\n",
        "        super(Attention,self).__init__()\n",
        "        self.emb2hid=nn.Linear(emb_size,hid_size)\n",
        "        self.hid2emb=nn.Linear(hid_size,emb_size)\n",
        "        self.scale=torch.sqrt(torch.FloatTensor([0.4])).to(device)\n",
        "    \n",
        "    def forward(self,dec_conved,embedd,en_conved,en_combined):\n",
        "\n",
        "        dec_conved = dec_conved.permute(0,2,1)\n",
        "        dec_conved_emb = self.hid2emb(dec_conved)\n",
        "\n",
        "        Q = (dec_conved_emb + embedd) * self.scale\n",
        "        energy = torch.matmul(Q, en_conved.permute(0,2,1))\n",
        "        a = F.softmax(energy, dim=2)\n",
        "\n",
        "        context = torch.matmul(a, en_combined)\n",
        "        context = self.emb2hid(context)\n",
        "        conved = (context + dec_conved) * self.scale\n",
        "\n",
        "        return a, conved.permute(0,2,1)"
      ],
      "metadata": {
        "id": "kVb0G5C0QkdN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock_Decod(nn.Module):\n",
        "   def __init__(self, emb_dim, hid_dim, pad_param1, pad_param2, device):\n",
        "      super().__init__()\n",
        "\n",
        "      self.pad_param1 = pad_param1\n",
        "      self.pad_param2 = pad_param2\n",
        "\n",
        "      # сверточные слои\n",
        "      self.conv1 = nn.Conv1d(in_channels=hid_dim, \n",
        "                               out_channels=hid_dim,\n",
        "                               kernel_size=3+2,\n",
        "                               padding = self.pad_param1)\n",
        "        \n",
        "      self.conv2 = nn.Conv1d(in_channels=hid_dim, \n",
        "                               out_channels=hid_dim,\n",
        "                               kernel_size=5,\n",
        "                               padding = self.pad_param2)\n",
        "      \n",
        "      self.batch_norm = nn.BatchNorm1d(hid_dim)\n",
        "\n",
        "      self.attent = Attention(emb_dim, hid_dim, device)\n",
        "\n",
        "      self.scale = torch.sqrt(torch.FloatTensor([0.4])).to(device)\n",
        "\n",
        "      self.activ = nn.ReLU()\n",
        "      self.device = device\n",
        "    \n",
        "\n",
        "   def forward(self, padded_seq, to_conv_perm, elem_wise, enc_output, enc_res_output):\n",
        "        # сверточные слои\n",
        "        conv1 = self.conv1(padded_seq)  # [batch, hid_dim, len_sent]\n",
        "        conv1 = self.batch_norm(conv1)\n",
        "        conv1 = self.activ(conv1)  # [batch, hid_dim, len_sent]\n",
        "\n",
        "        attentioned, out_conv = self.attent(conv1,elem_wise,enc_output,enc_res_output)\n",
        "\n",
        "        conv_after_resid = (to_conv_perm + out_conv) * self.scale  # [batch, hid_dim, len_sent]\n",
        "\n",
        "        conv2 = self.conv2(conv_after_resid)  # [batch, hid_dim, len_sent]\n",
        "        conv2 = self.batch_norm(conv2)\n",
        "        conv2 = self.activ(conv2)  # [batch, hid_dim, len_sent]\n",
        "\n",
        "        attentioned2, out_conv2 = self.attent(conv2,elem_wise,enc_output,enc_res_output)\n",
        "        conv_after_2resid = (conv_after_resid + out_conv2) * self.scale  # [batch, hid_dim, len_sent]\n",
        "        return conv_after_2resid, attentioned2"
      ],
      "metadata": {
        "id": "-7Q-BcmKcARe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, kernel_s, device, pad_idx=0, max_length=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.pad_idx = pad_idx\n",
        "        self.pad_param1 = 1\n",
        "        self.pad_param2 = 2\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.kern_s = kernel_s\n",
        "\n",
        "        # инициализируем эмбеддинги для токенов и их позиций (от первого токена до последнего)\n",
        "        self.position_embedding = nn.Embedding(max_length, emb_dim)\n",
        "        self.token_embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        # линейные слои\n",
        "        self.linear_toblock = nn.Linear(emb_dim, hid_dim)\n",
        "        self.linear_outblock = nn.Linear(hid_dim, emb_dim)\n",
        "        self.liner_out = nn.Linear(emb_dim, output_dim)\n",
        "\n",
        "        self.conv_blocks = ConvBlock_Decod(self.emb_dim, hid_dim, self.pad_param1, self.pad_param2, device)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.05)\n",
        "        self.device = device\n",
        "  \n",
        "\n",
        "    def forward(self, b_elem, enc_output, enc_res_output):\n",
        "\n",
        "        batch_size = b_elem.shape[0]  # размер батча \n",
        "        src_len = b_elem.shape[1]    # длина последовательности\n",
        "\n",
        "        # генерация матрицы тензора для позиций слов: [batch, len_sent]\n",
        "        posintion_t = torch.stack([torch.arange(0, src_len) for pos in range(batch_size)]).to(self.device)\n",
        "\n",
        "        # получаем эмбеддинги: [batch, len_sent, embed_dim]\n",
        "        tok_emb = self.token_embedding(b_elem.to(self.device))\n",
        "        pos_emb = self.position_embedding(posintion_t)\n",
        "\n",
        "        # elemenwise sum: [batch, len_sent, embed_dim]\n",
        "        elem_wise = tok_emb + pos_emb  # тут еще можно добавить дропаут\n",
        "        \n",
        "        # линейные слой: [batch, len_sent, hid_dim]\n",
        "        to_block = self.linear_toblock(elem_wise)\n",
        "\n",
        "        # входная размерность в conv - (N,C,L), где L - длина последоваетльности, С - число каналов \n",
        "        # [batch, hid_dim, len_sent]\n",
        "        to_conv_perm = to_block.permute(0, 2, 1)\n",
        "\n",
        "        # делаем паддинги\n",
        "        padding = torch.zeros(to_block.shape[0], to_block.shape[2], self.pad_param1+1).fill_(self.pad_idx).to(self.device)\n",
        "        # срезаем маркер конца предложения\n",
        "        padded_seq = torch.cat((padding, to_conv_perm), dim=2)\n",
        "\n",
        "        # # сверточные слои\n",
        "        conv_after_2resid, attentioned2 = self.conv_blocks(padded_seq, to_conv_perm, elem_wise, enc_output, enc_res_output)\n",
        "        \n",
        "        # смена размерности для линейного слоя\n",
        "        to_out_lin = conv_after_2resid.permute(0, 2, 1)  # [batch, len_sent, hid_dim]\n",
        "        \n",
        "        # линейный слой\n",
        "        out_lin = self.linear_outblock(to_out_lin)  # [batch, len_sent, emb_dim]\n",
        "        \n",
        "        drop = self.dropout(out_lin)\n",
        "        fn = self.liner_out(drop)\n",
        "        # # residual connection\n",
        "        # res_con_out = out_lin + elem_wise  # [batch, len_sent, emb_dim]\n",
        "\n",
        "        return fn, attentioned2"
      ],
      "metadata": {
        "id": "LQ7oQ_5bADxr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dencoder = Decoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, KERNEL_SIZE)\n",
        "# out, att = dencoder(y, out_lin, res_con)"
      ],
      "metadata": {
        "id": "7v9Nnqr8_973"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out.shape"
      ],
      "metadata": {
        "id": "iNXQjg0HU949"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# att.shape"
      ],
      "metadata": {
        "id": "VZkP08PIU_0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Seq2Seq(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim, enc_emb_dim, dec_emb_dim, hid_dim, kernel_s, device, pad_idx=0, max_length=64):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(input_dim, enc_emb_dim, hid_dim, kernel_s, device)\n",
        "        self.decoder = Decoder(output_dim, dec_emb_dim, hid_dim, kernel_s, device)\n",
        "  \n",
        "  def forward(self, sourse, target):\n",
        "\n",
        "        sourse_output, sourse_output_resid = self.encoder(x)\n",
        "\n",
        "        target_output, target_atten = self.decoder(target, sourse_output, sourse_output_resid)\n",
        "\n",
        "        return target_output, target_atten"
      ],
      "metadata": {
        "id": "19P4K24qVJGZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "-diM6dWOWlfm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = vocab_size\n",
        "OUTPUT_DIM = vocab_size\n",
        "KERNEL_SIZE = 2\n",
        "ENC_EMB_DIM = 300\n",
        "DEC_EMB_DIM = 300\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 1"
      ],
      "metadata": {
        "id": "BdgWC8CXWr2v"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN_Seq2Seq(INPUT_DIM, OUTPUT_DIM, ENC_EMB_DIM, DEC_EMB_DIM, HID_DIM, KERNEL_SIZE, device)"
      ],
      "metadata": {
        "id": "QKMtXnh8WmQL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UA3DwSWIHn7",
        "outputId": "4bf2db0b-a65a-43c1-d771-e12c27bec2c5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (position_embedding): Embedding(64, 300)\n",
              "    (token_embedding): Embedding(30000, 300)\n",
              "    (linear_toblock): Linear(in_features=300, out_features=512, bias=True)\n",
              "    (linear_outblock): Linear(in_features=512, out_features=300, bias=True)\n",
              "    (conv_b): ConvBlock(\n",
              "      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "      (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (position_embedding): Embedding(64, 300)\n",
              "    (token_embedding): Embedding(30000, 300)\n",
              "    (linear_toblock): Linear(in_features=300, out_features=512, bias=True)\n",
              "    (linear_outblock): Linear(in_features=512, out_features=300, bias=True)\n",
              "    (liner_out): Linear(in_features=300, out_features=30000, bias=True)\n",
              "    (conv_blocks): ConvBlock_Decod(\n",
              "      (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(1,))\n",
              "      (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "      (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (attent): Attention(\n",
              "        (emb2hid): Linear(in_features=300, out_features=512, bias=True)\n",
              "        (hid2emb): Linear(in_features=512, out_features=300, bias=True)\n",
              "      )\n",
              "      (activ): ReLU()\n",
              "    )\n",
              "    (dropout): Dropout(p=0.05, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "VCZnXI36XB22"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "\n",
        "losses = []\n",
        "predictions = []\n",
        "\n",
        "epoch_score_train = []\n",
        "epoch_score_test = []"
      ],
      "metadata": {
        "id": "lbD3Na0mXHvz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluating(dataloader, model, criterion, optimizer, n_epoch):\n",
        "    \n",
        "    losses = []\n",
        "    \n",
        "    print('Epoch #{}\\n'.format(n_epoch+1))\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    try:\n",
        "\n",
        "      progress_bar = tqdm(total=len(dataloader.dataset) / 64, desc='Epoch {}'.format(n_epoch + 1))\n",
        "\n",
        "      for x, y, y_no_eos in dataloader:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y_no_eos = y_no_eos.to(device)\n",
        "            \n",
        "            \n",
        "            output, _ = model(x, y_no_eos[:,:-1])\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            y = y[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            loss = criterion(output, y)\n",
        "            \n",
        "            # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            \n",
        "            # optimizer.step()\n",
        "            \n",
        "            losses.append(loss.item())\n",
        "          \n",
        "            progress_bar.update()\n",
        "            progress_bar.set_postfix(loss=np.mean(losses[-100:]))\n",
        "\n",
        "      progress_bar.close()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "\n",
        "        progress_bar.close()\n",
        "        # break\n",
        "    \n",
        "    print(f'\\tValidation Loss: {np.mean(losses[-100:])}')\n",
        "          \n",
        "    return np.mean(losses[-100:])"
      ],
      "metadata": {
        "id": "o4djnfofFKdb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(dataloader, model, criterion, optimizer, n_epoch, clip):\n",
        "    \n",
        "    losses = []\n",
        "    \n",
        "    print('Epoch #{}\\n'.format(n_epoch+1))\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    try:\n",
        "\n",
        "      progress_bar = tqdm(total=len(dataloader.dataset) / 64, desc='Epoch {}'.format(n_epoch + 1))\n",
        "\n",
        "      for x, y, y_no_eos in dataloader:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y_no_eos = y_no_eos.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output, _ = model(x, y_no_eos[:,:-1])\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            y = y[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            losses.append(loss.item())\n",
        "          \n",
        "            progress_bar.update()\n",
        "            progress_bar.set_postfix(loss=np.mean(losses[-100:]))\n",
        "\n",
        "      progress_bar.close()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "\n",
        "        progress_bar.close()\n",
        "        # break\n",
        "    \n",
        "    print(f'\\tTrain Loss: {np.mean(losses[-100:])}')\n",
        "          \n",
        "    return np.mean(losses[-100:])"
      ],
      "metadata": {
        "id": "HVk_q3cZBQ-Z"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(sentence, model, bos_index=2, eos_index=3, max_sequence=45):\n",
        "\n",
        "    tokenized = tokenizer.tokenize([sentence])\n",
        "\n",
        "    # добавляем тег начала предложения\n",
        "    tokenized[0].insert(0, bos_index)\n",
        "\n",
        "    # print(tokenized)\n",
        "    x = torch.tensor(tokenized).long().to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_conved, encoder_combined = model.encoder(x)\n",
        "\n",
        "\n",
        "    trg_indexes = [[bos_index]]\n",
        "\n",
        "    for i in range(max_sequence):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).to(device)\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, encoder_conved, encoder_combined)\n",
        "        pred_token = output.argmax(2)[:, -1].item()\n",
        "        trg_indexes[0].append(pred_token)\n",
        "        if pred_token == eos_index:\n",
        "            break\n",
        "\n",
        "    trg_tokens = tokenizer.tokenizer.decode(trg_indexes[0])\n",
        "\n",
        "    return ' '.join(trg_tokens)"
      ],
      "metadata": {
        "id": "fQysquOmYJg6"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate('Что мне купить сегодня вечером на ужин?', new_m.to(device), bos_index=2, eos_index=3, max_sequence=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HO4-CcF-KRLj",
        "outputId": "cddf2c75-e6d4-4529-ee17-cbf10a24c9c6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<BOS> у в не<EOS>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 7\n",
        "clip = 1\n",
        "\n",
        "try_sent = 'Что мне купить сегодня вечером на ужин?'\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    \n",
        "    # print('Epoch #{}\\n'.format(n_epoch+1))\n",
        "    try:\n",
        "    \n",
        "      \n",
        "      train_loss = training(train_loader, model, criterion, optimizer, epoch, clip)\n",
        "      valid_loss = evaluating(dev_loader, model, criterion, optimizer, epoch)\n",
        "      torch.save(model.state_dict(), 'cnntry2-model.pt')\n",
        "      print(generate(try_sent, model, bos_index=2, eos_index=3, max_sequence=20))\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDYYHygI7k61",
        "outputId": "3cbf949f-7bdf-47e5-e354-2870fb3b7deb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #1\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 5000/5000.0 [12:42<00:00,  6.56it/s, loss=0.0295]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.029535379901062697\n",
            "Epoch #1\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 625/625.0 [00:31<00:00, 20.11it/s, loss=0.0291]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tValidation Loss: 0.02907277975231409\n",
            "<BOS>самыйдоста подумали подумали подумали подумализрос шарапо мети шарапо подводит исполнитель разговаривает сортизрос переубедчч полюбому обучлс\n",
            "Epoch #2\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 5000/5000.0 [12:45<00:00,  6.53it/s, loss=0.00711]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.00711050744401291\n",
            "Epoch #2\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 625/625.0 [00:31<00:00, 20.12it/s, loss=0.00987]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tValidation Loss: 0.009868265315890312\n",
            "<BOS>самый зубы? зубы? верите, чувств? резю ума? карьеру 4? мети выдержа питомцы верите, свету ума? ближайшиеваете, около изменяли ума?\n",
            "Epoch #3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 5000/5000.0 [12:47<00:00,  6.51it/s, loss=0.0026]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.0025975851459952536\n",
            "Epoch #3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 625/625.0 [00:31<00:00, 19.94it/s, loss=0.00818]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tValidation Loss: 0.008181838339660318\n",
            "<BOS>кемкемкемкемкемкемкемкемкемкемкемкемкемкемкемкемкем одинокаякемкем\n",
            "Epoch #4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 5000/5000.0 [12:47<00:00,  6.52it/s, loss=0.00105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.0010480748274494544\n",
            "Epoch #4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 625/625.0 [00:31<00:00, 19.97it/s, loss=0.00791]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tValidation Loss: 0.007905942446086556\n",
            "<BOS> проводитекемнглий проводите назвали? увидев проводите ксезросле жизни.?кемвым?мальчи$$ поцелуя? кадру дарить?ненко ассоциации. тот.\n",
            "Epoch #5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 5000/5000.0 [12:49<00:00,  6.49it/s, loss=0.000436]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.0004362995236442657\n",
            "Epoch #5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 625/625.0 [00:31<00:00, 19.80it/s, loss=0.00542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tValidation Loss: 0.005416717672487721\n",
            "<BOS> одному?линей!)?人 вечером?ₐ различие предпочитаете? предпочитаете?人линей посоветуете?人人 вечером?此сировать волосами?ₐ人\n",
            "Epoch #6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 5000/5000.0 [12:47<00:00,  6.51it/s, loss=0.000315]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.0003149024386766541\n",
            "Epoch #6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 625/625.0 [00:31<00:00, 20.01it/s, loss=0.00917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tValidation Loss: 0.009173334959195928\n",
            "<BOS> небо? свадьбы?ever месяца?руете? свадьбы? волосами? ума? вашему, безал знаете?) романтики? ег расшифровы лансер телосло вашему,㋛ романтики? месяца?\n",
            "Epoch #7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 5000/5000.0 [12:44<00:00,  6.54it/s, loss=0.000362]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.0003619438811665532\n",
            "Epoch #7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 625/625.0 [00:31<00:00, 20.00it/s, loss=0.0234]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tValidation Loss: 0.023414298074203543\n",
            "<BOS>ги? зарплату?вает?) готовлю отдал носить? выходилигарита зарплата? носить? питомцы.как лечи таки,.если菲ки\"?ваете,вает?) школе,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_seq2seq.pt')"
      ],
      "metadata": {
        "id": "NmiTrqscgDA5"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_m = CNN_Seq2Seq(INPUT_DIM, OUTPUT_DIM, ENC_EMB_DIM, DEC_EMB_DIM, HID_DIM, KERNEL_SIZE, device)\n",
        "new_m.load_state_dict(torch.load('/content/drive/MyDrive/комплинг/дз3/model_seq2seq.pt'))\n",
        "new_m.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T91pNC1MEtqZ",
        "outputId": "eb50ee2e-a1af-4eb4-8df8-377fc0ea1289"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (position_embedding): Embedding(64, 300)\n",
              "    (token_embedding): Embedding(30000, 300)\n",
              "    (linear_toblock): Linear(in_features=300, out_features=512, bias=True)\n",
              "    (linear_outblock): Linear(in_features=512, out_features=300, bias=True)\n",
              "    (conv_b): ConvBlock(\n",
              "      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "      (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (position_embedding): Embedding(64, 300)\n",
              "    (token_embedding): Embedding(30000, 300)\n",
              "    (linear_toblock): Linear(in_features=300, out_features=512, bias=True)\n",
              "    (linear_outblock): Linear(in_features=512, out_features=300, bias=True)\n",
              "    (liner_out): Linear(in_features=300, out_features=30000, bias=True)\n",
              "    (conv_blocks): ConvBlock_Decod(\n",
              "      (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(1,))\n",
              "      (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "      (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (attent): Attention(\n",
              "        (emb2hid): Linear(in_features=300, out_features=512, bias=True)\n",
              "        (hid2emb): Linear(in_features=512, out_features=300, bias=True)\n",
              "      )\n",
              "      (activ): ReLU()\n",
              "    )\n",
              "    (dropout): Dropout(p=0.05, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    'если',\n",
        "    'кто',\n",
        "    'что делать, если',\n",
        "    'почему мне так плохо',\n",
        "    'как купить машину',\n",
        "    'если я буду платить в кино, то что будет?',\n",
        "    'как зовут моего кота?',\n",
        "    'как выглядит совместная жизнь?',\n",
        "    'почему меня презирают в школе?', \n",
        "    'где лучше всего отметить день рождения?',\n",
        "    'как закончить магистратуру?', \n",
        "    'если завтра станет тепло, '\n",
        "    'как мне усопокиться?',\n",
        "    'что сделать, чтобы отметить новый год'\n",
        "]"
      ],
      "metadata": {
        "id": "fGMBhqyTZuZI"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in sentences:\n",
        "  print('Вопрос: ', sent)\n",
        "  print('Ответ: ', generate(sent, model, bos_index=2, eos_index=3, max_sequence=20).replace('<BOS>', ''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSh9oAiOT7Cf",
        "outputId": "5c022905-93f9-42d1-e783-4fbbcb93d5ab"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вопрос:  если\n",
            "Ответ:  вым? обстоят (фото питомцы.как катего напле питомцы отдал галан живопи питомцыги?ником?) неизлечи пустое питомцы волосами?вает?)ите!\n",
            "Вопрос:  кто\n",
            "Ответ:  вым? обстоят (фото питомцы выходили предпочитаете? обстоятги? питомцыs, галан катего свит клички обстоят выходилитон, зарплата?вает?) обстоят\n",
            "Вопрос:  что делать, если\n",
            "Ответ:  вым? обстоят (фото питомцы.как катего напле питомцы отдал галан живопи питомцыги?ником?) неизлечи пустое питомцы волосами?вает?)ите!\n",
            "Вопрос:  почему мне так плохо\n",
            "Ответ:   носить?== зарплата? питомцыпродолжитеником?) отдал метивает?) готовлю живопи лечи питомцы.еслиником?) носить? выходили (фото питомцыпродолжите\n",
            "Вопрос:  как купить машину\n",
            "Ответ:  вым? обстоят (фото питомцы.как катего напле питомцы отдал галан живопи питомцыги?ником?) неизлечи пустое питомцы волосами?вает?)ите!\n",
            "Вопрос:  если я буду платить в кино, то что будет?\n",
            "Ответ:  вым? зарплата? (фото питомцы.как (фото (фото (фото фортепи опозна выбирает питомцы此 иметь? кличкипродолжитеником?) одинокая (фотогарита\n",
            "Вопрос:  как зовут моего кота?\n",
            "Ответ:  вым? обстоят (фото питомцытон,ником?) що питомцы мети живопи питомцыги? лечи питомцы галан носить? носить? опозна обстоятфа?\n",
            "Вопрос:  как выглядит совместная жизнь?\n",
            "Ответ:  вым? обстоят (фото питомцы.как катего напле питомцы отдал галан живопи питомцыги?ником?) неизлечи пустое питомцы волосами?вает?)ите!\n",
            "Вопрос:  почему меня презирают в школе?\n",
            "Ответ:   зарплата? делся обстоят живопи выходили зарплата? делсяпродолжите ?=) (фото (фото готовите поможет? пустое живопи носить? зарплата?гарита тепло? (фото\n",
            "Вопрос:  где лучше всего отметить день рождения?\n",
            "Ответ:   зарплата? делся обстоят живопи выходили зарплата? делсяпродолжите ?=) (фото (фото готовите поможет? пустое живопи носить? зарплата?гарита тепло? (фото\n",
            "Вопрос:  как закончить магистратуру?\n",
            "Ответ:   зарплата? делся обстоят живопи выходили зарплата? делсяпродолжите ?=) (фото (фото готовите поможет? пустое живопи носить? зарплата?гарита тепло? (фото\n",
            "Вопрос:  если завтра станет тепло, как мне усопокиться?\n",
            "Ответ:   носить? безал (фото питомцы утром? лечи питомцы мужики! лечи питомцы волосами? (фото питомцы сейчас?) обстоят лечи питомцы.еслиником?)ите!\n",
            "Вопрос:  что сделать, чтобы отметить новый год\n",
            "Ответ:   зарплата? делся обстоят живопи выходили зарплата? делсяпродолжите ?=) (фото (фото готовите поможет? пустое живопи носить? зарплата?гарита тепло? (фото\n"
          ]
        }
      ]
    }
  ]
}